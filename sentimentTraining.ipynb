{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimentTraining.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3WJe3vvqZ4NSLQTuIN/Qh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krmonline/Sentiment-Analysis-in-Social-Networks/blob/master/sentimentTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9p8zUKSzbdy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "10935c62-bf9d-470f-80f8-3a305ac9b075"
      },
      "source": [
        "!pip install pythainlp\n",
        "!pip install emoji\n",
        "!pip install deepcut"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pythainlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/14/b80930a2cc09ed6b5f8a22da9be6ece56939839ae66d921d9c7123034ba0/pythainlp-2.1.4-py3-none-any.whl (11.1MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1MB 8.2MB/s \n",
            "\u001b[?25hCollecting tinydb>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/f6/b3e112addc8eb4a097f158124ce8b206767361a381f80c5f0c506d855e4a/tinydb-4.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.1 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (4.41.1)\n",
            "Collecting nltk>=3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (0.3.1.1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->pythainlp) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->pythainlp) (0.15.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->pythainlp) (2019.12.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2.9)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434674 sha256=33d9b637324973832c0dc8f563d8ed8c6dc6bd90fb799ed708733ad0c8a59893\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "Successfully built nltk\n",
            "Installing collected packages: tinydb, nltk, pythainlp\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.5 pythainlp-2.1.4 tinydb-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cFbe6l20cxw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5466e17b-f82e-48f3-fddd-51f2cafffa46"
      },
      "source": [
        "!pip install visualize"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement visualize (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for visualize\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n27mSkHyU8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pythainlp.tokenize\n",
        "import deepcut"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9SQMmInyZ9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_df = pd.read_csv(\"https://raw.githubusercontent.com/PyThaiNLP/wisesight-sentiment/master/kaggle-competition/train.txt\",names=['texts'])\n",
        "all_df['lab'] = pd.read_csv(\"https://raw.githubusercontent.com/PyThaiNLP/wisesight-sentiment/master/kaggle-competition/train_label.txt\",names=['lab'])\n",
        "test_df = pd.read_csv(\"https://raw.githubusercontent.com/PyThaiNLP/wisesight-sentiment/master/kaggle-competition/test.txt\",names=['texts'])\n",
        "test_df['real'] = pd.read_csv(\"https://raw.githubusercontent.com/PyThaiNLP/wisesight-sentiment/master/kaggle-competition/test_label.txt\",names=['real'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdSzGyoAzSZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_df[\"processed\"] = all_df.texts.map(lambda x: \"|\".join(pythainlp.tokenize.word_tokenize(x,engine='deepcut')))\n",
        "test_df[\"processed\"] = test_df.texts.map(lambda x: \"|\".join(pythainlp.tokenize.word_tokenize(x,engine='deepcut')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAWcgiWr0-fp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "407dfd20-12fa-4608-b543-ae1b62000cd7"
      },
      "source": [
        "all_df.lab.value_counts() / all_df.shape[0]"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neu    0.544612\n",
              "neg    0.255164\n",
              "pos    0.178698\n",
              "q      0.021527\n",
              "Name: lab, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4hF6LTR7adD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizerPipe(x):\n",
        "  return x.split('|')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbw9Dv1E67Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#text faetures\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-USV2VmI7NQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f699c350-58f9-487f-eb21-c1a6f1aa962e"
      },
      "source": [
        "tfidf = TfidfVectorizer(tokenizer=tokenizerPipe, ngram_range=(1,2), min_df=20, sublinear_tf=True)\n",
        "tfidf_fit = tfidf.fit(pd.concat([all_df[\"processed\"],test_df['processed']]))\n",
        "text_train = tfidf_fit.transform(all_df[\"processed\"])\n",
        "#text_valid = tfidf_fit.transform(valid_df[\"texts\"])\n",
        "text_test = tfidf_fit.transform(test_df[\"processed\"])\n",
        "text_train.shape, text_test.shape"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((24063, 5938), (2674, 5938))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x83Bs-Gb8P4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bA65t329Fv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detect_model = MultinomialNB().fit(text_train,all_df['lab'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnmV6wUu9m5F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "79a18f92-698a-49cb-abd8-a4b02497ce42"
      },
      "source": [
        "cid = 100\n",
        "print(test_df.iloc[cid]['processed'])\n",
        "_=tfidf_fit.transform([test_df.iloc[cid]['processed']]).toarray()\n",
        "print(detect_model.predict(_)[0])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "กิน|เบื่อ|แระ\n",
            "neg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv0mpg439rLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = detect_model.predict(text_test)\n",
        "test_df['pred'] = pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHDTBtJq-ag8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real = test_df['real'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQwj62B4-q9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1QbhrOZ_hI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "707e9f6a-d5f7-4bf0-d487-0f0f26503cb6"
      },
      "source": [
        "print(classification_report(real,pred))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.67      0.70      0.68       683\n",
            "         neu       0.70      0.84      0.76      1456\n",
            "         pos       0.63      0.28      0.39       478\n",
            "           q       0.00      0.00      0.00        57\n",
            "\n",
            "    accuracy                           0.68      2674\n",
            "   macro avg       0.50      0.45      0.46      2674\n",
            "weighted avg       0.66      0.68      0.66      2674\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1di94RzBpxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e0a79a85-28c9-4916-da3e-f16edaad4271"
      },
      "source": [
        "test_df[test_df.pred == 'pos']"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>real</th>\n",
              "      <th>processed</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>จะเกมส์ได้ไง ผมเลิกแล้ว ไปๆๆ</td>\n",
              "      <td>neu</td>\n",
              "      <td>จะ|เกมส์|ได้|ไง| |ผม|เลิก|แล้ว| |ไป|ๆ|ๆ</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>น่าสนๆ เราไปลองพร้อมกันดีไหมคะ มื้อเที่ยงวันสา...</td>\n",
              "      <td>pos</td>\n",
              "      <td>น่า|สน|ๆ| |เรา|ไป|ลอง|พร้อม|กัน|ดี|ไหม|คะ| |มื...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>อยากกินชีสเหมือนกัน5555</td>\n",
              "      <td>pos</td>\n",
              "      <td>อยาก|กิน|ชีส|เหมือน|กัน|5555</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>เทคนิคป้องกันแสงแดดที่ฟ้าจะแนะนำเพื่อนๆ คือ ก่...</td>\n",
              "      <td>pos</td>\n",
              "      <td>เทคนิคป้องกัน|แสง|แดด|ที่|ฟ้า|จะ|แนะนำ|เพื่อน|...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>น่าลองน๊า</td>\n",
              "      <td>pos</td>\n",
              "      <td>น่า|ลองน๊า</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2565</th>\n",
              "      <td>อยากสวยเหมือน เกรท กาญเกล้า ผิวก็สวย หน้าก็ใส ...</td>\n",
              "      <td>neu</td>\n",
              "      <td>อยาก|สวย|เหมือน| |เกรท กาญเกล้า| |ผิว|ก็|สวย| ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2569</th>\n",
              "      <td>แค่ชื่อก็น่ากินแล้ว</td>\n",
              "      <td>pos</td>\n",
              "      <td>แค่|ชื่อ|ก็|น่า|กิน|แล้ว</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2601</th>\n",
              "      <td>หิววว บาบีก้อนก็อยากกก</td>\n",
              "      <td>neu</td>\n",
              "      <td>หิววว| |บาบีก้อน|ก็|อยาก|กก</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2607</th>\n",
              "      <td>ยกยอดให้ซีวิคไปเลย สบายๆไ</td>\n",
              "      <td>neu</td>\n",
              "      <td>ยก|ยอด|ให้|ซีวิค|ไป|เลย| |สบาย|ๆ|ไ</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2625</th>\n",
              "      <td>ไปวันไหนได้ละจ่ะ</td>\n",
              "      <td>neu</td>\n",
              "      <td>ไป|วัน|ไหน|ได้|ละ|จ่ะ</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texts  ... pred\n",
              "42                         จะเกมส์ได้ไง ผมเลิกแล้ว ไปๆๆ  ...  pos\n",
              "65    น่าสนๆ เราไปลองพร้อมกันดีไหมคะ มื้อเที่ยงวันสา...  ...  pos\n",
              "66                              อยากกินชีสเหมือนกัน5555  ...  pos\n",
              "74    เทคนิคป้องกันแสงแดดที่ฟ้าจะแนะนำเพื่อนๆ คือ ก่...  ...  pos\n",
              "75                                            น่าลองน๊า  ...  pos\n",
              "...                                                 ...  ...  ...\n",
              "2565  อยากสวยเหมือน เกรท กาญเกล้า ผิวก็สวย หน้าก็ใส ...  ...  pos\n",
              "2569                                แค่ชื่อก็น่ากินแล้ว  ...  pos\n",
              "2601                             หิววว บาบีก้อนก็อยากกก  ...  pos\n",
              "2607                          ยกยอดให้ซีวิคไปเลย สบายๆไ  ...  pos\n",
              "2625                                   ไปวันไหนได้ละจ่ะ  ...  pos\n",
              "\n",
              "[216 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFFTqBnFBqHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}